# dev note
## 書き方
- 上から優先順位順、mustは絶対やりたい、betterは後回し
- 実施日付を##でつける
- 終わったらdを行の先頭につける

## must
### 3/30
d-既存モデルのロードして追加学習
d- early stoppingの追加と切り替え
d- tensorflowモデルに変換/torchプログラム追加し、学習したモデルがdonkeyでそのまま動くようにする
d- 学習時にスキップデータ数を選択
d- モデルとパラメータの管理、mlflow

### 4/1
d- モデルの保存場所を現在フォルダの中にあるmodelsへ変更
d- sessionのフォルダ名変更：annotation_tool→sessions

### 4/4
d- ultralycsの物体検知検知モデルの学習機能追加とそのためのアノテーション機能の追加を行い、下記のUIを導入する。
    - 可能であれば通常のアノテーションもできるようにしたいので、何かキーを押してバウンディングボックスのアノテーションと切り替えられるようする
    - 検知する物体のリストを簡単に入力できるようにし、データ出力もできるようにする
    - 物体検知モデルも切り替えられるようにする

d- 前回アノテーション時に選んだ物体検知クラスを記録しておき、次のアノテーションの初期候補とする
d- アノテモードのラベルの下にチェックボックスを追加し、チェックが入っているときは、前回選んだ物体検知アノテーションを今回の画像に対しても適用する
d- 現在の画像に適応してあるアノテーションをクリックしながらドラッグし移動できるようにする
d- yoloモデルの一覧を起動時から読んで置き、あれば一番上を表示しておく

### 4/11
d-複数フォルダを読み込み（対象フォルダの下のimagesとアノテーションデータをターゲットにする）
d 読み込んだ画像からモデルのinput_size決定
d-学習後のオーグメンテーション関連変数エラー解消
d-ボタン一部修正

### 4/12
- mlrun機能拡張と保存フォルダの変更
- 

###
- 説明更新

## better
- コース位置情報のラベルの下にチェックボックスを追加し、チェックが入っているときは、前回選んだ位置を今回の画像に対しても適用する
-セマンティックセグメンテーションのアノテーション
- 位置情報から、位置情報推論モデルを作成ボタン
- 位置選択を自動アノテーションチェックボックスで、次の画像にいったときも自動選択
- donkeyカスタムモデルの画像サイズが読み込んだ画像サイズに合わせて変更
- 横縦に-1~1の数字いれる
- CSSの書き出し＋テーマを選べるようにする 
- （lidar画像吐き出ししてから）
    - ２画像の連動読み出し
    - ２画像モデル構築
- セマンティックセグメンテーション？


## test
- pytorchのモデルで走行テスト、特に推論間に合うか
- catalogとかの配置がうまくいっているか確認し、学習が進むか確認。
- donkeyで変換したh5が動くか確認




